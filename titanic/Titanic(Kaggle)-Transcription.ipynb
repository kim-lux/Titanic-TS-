{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 라이브러리 불러오기\n",
    "    - 우선 코드를 작성하기에 앞서 기초적으로 필요한 라이브러리를 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리를 우선 불러옵니다.\n",
    "\n",
    "## 데이터 분석 관련\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "\n",
    "## 데이터 시각화 관련\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid') # matplotlib의 스타일에 관련한 함\n",
    "## 그래프 출력에 필요한 IPython 명령어\n",
    "%matplotlib inline \n",
    "\n",
    "## Scikit-Learn의 다양한 머신러닝 모듈을 불러옵니다.\n",
    "## 분류 알고리즘 중에서 선형회귀, 서포트벡터머신, 랜덤포레스트, K-최근접이웃 알고리즘을 사용해보려고 합니다.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 데이터 읽기\n",
    "    - Kaggle 또는 데이터 분석에서 가장 많이 사용되는 파일 형식은 CSN 파일입니다.\n",
    "    코드로 데이터를 읽는 방법은 다양한 방법이 있지만, 그 중에서도 가장 유용한 것은 pd.read_csv로 읽는 방법입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 우선 가져와야합니다.\n",
    "train_df = pd.read_csv(\"C:/Users/1/python/titanic/train.csv\")\n",
    "test_df = pd.read_csv(\"C:/Users/1/python/titanic/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#데이터 미리보기\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 정보에서 번호는 큰 의미를 가지지 않고, 이름과 티겟의 경우에는 불규칙성이 많아 처리하기 어려울 것 같습니다. 데이터의 정보는 info 메서드로 확인할 수 있습니다. 훈련 데이터와 테스트 데이터를 확인해보도록 하겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "--------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()\n",
    "print('-'*20)\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 결과에서 각각의 데이터 개수는 891개, 418개인 것을 확인할 수 있습니다. 특성은 각각 12개, 11개 입니다. 그 이유는 \n",
    "훈련 데이터는 생존 여부를 알고 있기 때문입니다.\n",
    "\n",
    "여기서 주의깊게 봐야할 부분은 다음과 같습니다.\n",
    "\n",
    "- 각 데이터는 빈 부분이 있는가?\n",
    "    - 빈 부분이 있다면, Drop할 것 인가 아니면 Default값으로 채워넣을 것인가\n",
    "    - Cabin, Age, Embarked 세 항목에 주의\n",
    "- 데이터는 Float64로 변환할 수 있는가\n",
    "    - 아니라면 범주형 데이터로 만들 수 있는가\n",
    "    \n",
    "필요없는 부분이라고 생각되는 부분을 지웁니다. 여기서는 PassengerID와 이름, 티켓을 지웁니다. 이름과 티켓에서 가져올 수 있는 \n",
    "데이터는 없기 때문입니다. 하지만 이 문제에서 결과물은 'PassengerID', 'Survived' 요소가 필요하므로 훈련 데이터에서만 \n",
    "삭제합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(['PassengerId', 'Name', 'Ticket'], axis=1)\n",
    "test_df = test_df.drop(['Name', 'Ticket'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "axis = 0 (index) ->> 행 방향으로 동작합니다., 작업 결과가 행으로 나타납니다.. 책을 위로 쌓아 정리하는 것과 같습니다.\n",
    "\n",
    "axis = 1 (columns) ->> 열 방향으로 동작합니다., 작업 결과가 열으로 나타납니다.. 책을 옆으로 쌓아 정리하는 것과 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 데이터 하나하나 처리하기\n",
    " 이제 남은 데이터의 종류는 다음과 같습니다.\n",
    " 1. Pclass\n",
    " 2. Sex\n",
    " 3. Age\n",
    " 4. SibSp\n",
    " 5. Parch\n",
    " 6. Fare\n",
    " 7. Cabin\n",
    " 8. Embarked\n",
    " \n",
    " 이제 순서대로 보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Pclass\n",
    "\n",
    "Pclass는 서수형 데이터입니다.1등석, 2등석, 3등석과 같은 정보입니다. 처음에 확인시에 데이터가 비어있지 않은 것을 확인할 수\n",
    "있었습니다.\n",
    "\n",
    "데이터에 대한 확인과 데이터를 반환해보도록 하겠습니다. 우선 각 Unique한 Value에 대한 카운팅은 Value_counts() 메서드로 확인할\n",
    "수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    491\n",
       "1    216\n",
       "2    184\n",
       "Name: Pclass, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Pclass'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1,2,3 은 정수이니, 그냥 실수로만 바꾸면 되지않을까 생각할 수 있습니다. 하지만 1, 2, 3 등급은 경우에 따라 다를 수 있지만\n",
    "연속적인 정보가 아니며, 각 차이 또한 균등하지 않습니다. 그렇기에 범주형(카테고리) 데이터로 인식하고 인코딩해야 합니다.\n",
    "(비슷한 예시로 영화 별점 등이 있습니다.)\n",
    "\n",
    "이 데이터는 범주형 데이터 이므로 one-hot-encoding을 pd.get_dummies() 메서드로 인코딩합시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pclass_train_dummies = pd.get_dummies(train_df['Pclass'])\n",
    "pclass_test_dummies = pd.get_dummies(test_df['Pclass'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(['Pclass'], axis=1,inplace = True)\n",
    "test_df.drop(['Pclass'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.join(pclass_train_dummies)\n",
    "test_df = test_df.join(pclass_test_dummies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 Pclass의 원본을 없애고, 범주형으로 개별로 데이터가 변환되었습니다.\n",
    "* 여기서 살짝 실수한게 columns의 이름을 설정하고, 넣어줘야하는데 안그래서 1,2,3 이라는 컬럼으로 데이터가 들어갔습니다.\n",
    "    다른 데이터에서는 이런 적용을 피하도록 합시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Sex\n",
    "\n",
    "Sex는 성별입니다. 남과 여로 나뉘므로 이 또한 one-hot-encoding을 진행해봅시다.\n",
    "\n",
    "원-핫 인코딩은 단어 집합의 크기를 벡터의 차원으로 하고, 표현하고 싶은 단어의 인덱스에 1의 값을 부여하고, 다른 인덱스에는 0을 부여하는 단어의 벡터 표현 방식입니다. 이렇게 표현된 벡터를 원-핫 벡터(One-Hot vector)라고 합니다.\n",
    "\n",
    "원-핫 인코딩을 두 가지 과정으로 정리해보겠습니다.\n",
    "\n",
    "(1) 각 단어에 고유한 인덱스를 부여합니다. (정수 인코딩)\n",
    "\n",
    "(2) 표현하고 싶은 단어의 인덱스의 위치에 1을 부여하고, 다른 단어의 인덱스의 위치에는 0을 부여합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_train_dummies = pd.get_dummies(train_df['Sex'])\n",
    "sex_test_dummies = pd.get_dummies(test_df['Sex'])\n",
    "\n",
    "sex_train_dummies.columns = ['Female', 'Male']\n",
    "sex_test_dummies.columns = ['Female', 'Male']\n",
    "\n",
    "train_df.drop(['Sex'], axis=1,inplace = True)\n",
    "test_df.drop(['Sex'], axis=1, inplace = True)\n",
    "\n",
    "train_df = train_df.join(sex_train_dummies)\n",
    "test_df = test_df.join(sex_test_dummies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Age\n",
    "\n",
    "나이는 연속형 데이터이므로, 큰 처리가 필요없습니다. (카테고리화를 하여 일부 알고리즘에 더 유용한 결과를 만들 수 있습니다.)\n",
    "하지만 일부 NaN 데이터가 있으니 이를 채울 수 있는 방법에 대해서 생각해봅시다.\n",
    "\n",
    "1. 랜덤\n",
    "2. 평균값\n",
    "3. 중간값\n",
    "4. 데이터 버리기\n",
    "\n",
    "저는 일단은 평균값으로 채우도록 하겠습니다. 데이터의 통일성을 가지기 위해 train 데이터셋의 평균값으로 훈련, 테스트 데이터셋을 채우겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Age\"].fillna(train_df[\"Age\"].mean() , inplace=True)\n",
    "test_df[\"Age\"].fillna(train_df[\"Age\"].mean() , inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4 SibSP & Panch\n",
    "\n",
    "형제 자매와 부모님은 가족으로 함께 처리할 수 있습니다. 하지만 마찬가지로 바꿀 필요는 없습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.5 Fare\n",
    "\n",
    "Fare은 탑승료입니다. 신기하게 test 데이터셋에 1개의 데이터가 비어있습니다. 아마 디카프리오인듯 합니다. :-) 우선 빈 부분을 \n",
    "fillna 메서드로 채우겠습니다.\n",
    "\n",
    "저는 데이터 누락이 아닌 무단 탑승이라 생각하고 0으로 입력하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"Fare\"].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.6 Cabin\n",
    "\n",
    "Cabin은 객실입니다. NaN이 대부분인 데이터이므로 버립시다. 이 데이터를 살리는 것은 너무 어려운 일입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(['Cabin'], axis=1)\n",
    "test_df = test_df.drop(['Cabin'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.7 Embarked\n",
    "\n",
    "Embarked는 탑승 항구를 의미합니다. 우선 데이터를 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S    644\n",
       "C    168\n",
       "Q     77\n",
       "Name: Embarked, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Embarked'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S    270\n",
       "C    102\n",
       "Q     46\n",
       "Name: Embarked, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['Embarked'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S가 대다수이고 일부 데이터가 비어있는 것을 알 수 있습니다. 빈 부분은 S로 우선 채우고 시작합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Embarked\"].fillna('S' , inplace = True)\n",
    "test_df[\"Embarked\"].fillna('S' , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "embarked_train_dummies = pd.get_dummies(train_df['Embarked'])\n",
    "embarked_test_dummies = pd.get_dummies(test_df['Embarked'])\n",
    "\n",
    "embarked_train_dummies.columns = ['S', 'C', 'Q']\n",
    "embarked_test_dummies.columns = ['S', 'C', 'Q']\n",
    "\n",
    "train_df.drop(['Embarked'], axis=1, inplace=True)\n",
    "test_df.drop(['Embarked'], axis=1, inplace=True)\n",
    "\n",
    "train_df = train_df.join(embarked_train_dummies)\n",
    "test_df = test_df.join(embarked_test_dummies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 데이터 나누기\n",
    "\n",
    "이제 학습용 데이터를 위해 데이터를 나누어야합니다.\n",
    "\n",
    "(정보, 생존 여부) 와 같은 형태를 위하여 다음과 같이 데이터를 나눕니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(\"Survived\", axis=1)\n",
    "Y_train = train_df[\"Survived\"]\n",
    "X_test = test_df.drop(\"PassengerId\", axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of            Age  SibSp  Parch     Fare  1  2  3  Female  Male  S  C  Q\n",
       "0    22.000000      1      0   7.2500  0  0  1       0     1  0  0  1\n",
       "1    38.000000      1      0  71.2833  1  0  0       1     0  1  0  0\n",
       "2    26.000000      0      0   7.9250  0  0  1       1     0  0  0  1\n",
       "3    35.000000      1      0  53.1000  1  0  0       1     0  0  0  1\n",
       "4    35.000000      0      0   8.0500  0  0  1       0     1  0  0  1\n",
       "..         ...    ...    ...      ... .. .. ..     ...   ... .. .. ..\n",
       "886  27.000000      0      0  13.0000  0  1  0       0     1  0  0  1\n",
       "887  19.000000      0      0  30.0000  1  0  0       1     0  0  0  1\n",
       "888  29.699118      1      2  23.4500  0  0  1       1     0  0  0  1\n",
       "889  26.000000      0      0  30.0000  1  0  0       0     1  1  0  0\n",
       "890  32.000000      0      0   7.7500  0  0  1       0     1  0  1  0\n",
       "\n",
       "[891 rows x 12 columns]>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 머신러닝 알고리즘 적용하기\n",
    "\n",
    "이제 로지스틱 회귀, SVC, 랜덤포레스트,  K-최근접 이웃 알고리즘을 각각 적용해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8047138047138047"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = logreg.predict(X_test)\n",
    "\n",
    "logreg.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6868686868686869"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Support Vector Machines\n",
    "\n",
    "svc = SVC()\n",
    "\n",
    "svc.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = svc.predict(X_test)\n",
    "\n",
    "svc.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9820426487093153"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forests\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "random_forest.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = random_forest.predict(X_test)\n",
    "\n",
    "random_forest.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.835016835016835"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "\n",
    "knn.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = knn.predict(X_test)\n",
    "\n",
    "knn.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. 제출용 파일 만들기\n",
    "\n",
    "랜덤 포레스트가 가장 좋은 결과를 내는 것을 알 수 있습니다. 그 결과로 Submission 파일을 만들어 제출해 봅시다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forests\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(X_train, Y_train)\n",
    "Y_pred = random_forest.predict(X_test)\n",
    "random_forest.score(X_train, Y_train)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"PassengerId\" : test_df[\"PassengerId\"],\n",
    "    \"Survived\" : Y_pred\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('titanic.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
